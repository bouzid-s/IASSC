{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:15px 50px; padding:15px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#2a6199; overflow:hidden\"><b>  üß†  TP 3.1 -  Calcul Acc√©l√©r√©e avec CUDA Python (NUMBA) </b> \n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:10px; color:white; margin:10px 0; font-size:110%; font-family:Arial, sans-serif; background-color: #4682b4;\"><b>1. Introduction √† CUDA en Python avec Numba</b></div>\n",
    "\n",
    "\n",
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #f17c12; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "## <div style=\"  background-color:rgba(136, 125, 125, 0.15); text-align:left; border-radius:6px; padding:px; color:white; margin:5px 0; font-size:70%; font-family:Arial, sans-serif; background-color: #f17c12;\"><b>1.1 CUDA </b> </div>\n",
    "\n",
    "\n",
    "**[CUDA](https://fr.wikipedia.org/wiki/CUDA)**  (Compute Unified Device Architecture)** est une plateforme de calcul parall√®le et un mod√®le de programmation d√©velopp√© par **NVIDIA**. Elle permet aux d√©veloppeurs d'exploiter la puissance des **GPU (Graphics Processing Units)** pour ex√©cuter des calculs massivement parall√®les, bien au-del√† du rendu graphique.\n",
    "\n",
    "###  üìå Principales caract√©ristiques de CUDA :\n",
    "- **Ex√©cution parall√®le massive** : CUDA permet d‚Äôex√©cuter des milliers de threads en parall√®le, optimisant ainsi les performances pour les calculs intensifs.\n",
    "- **Mod√®le de programmation bas√© sur C/C++ et Python** : CUDA offre une interface de programmation proche du langage C/C++, et peut √™tre utilis√© avec des biblioth√®ques Python comme **Numba** et **CuPy**.\n",
    "- **Hi√©rarchie des threads et m√©moire optimis√©e** : CUDA organise l‚Äôex√©cution en blocs et grilles de threads, et exploite diff√©rentes m√©moires (globale, partag√©e, constante) pour maximiser l‚Äôefficacit√©.\n",
    "- **Interop√©rabilit√© avec des biblioth√®ques d‚ÄôIA et de calcul scientifique** : CUDA est utilis√© dans de nombreuses applications, notamment en **deep learning (TensorFlow, PyTorch)**, **simulation num√©rique**, **traitement d‚Äôimage** et **finance quantitative**.\n",
    "\n",
    "### üöÄ Pourquoi utiliser CUDA ?\n",
    "- Acc√©l√©ration des calculs par rapport aux CPU traditionnels.\n",
    "- Optimisation des performances pour des applications exigeantes.\n",
    "- Large √©cosyst√®me et support des biblioth√®ques de calcul parall√®le.\n",
    "\n",
    "CUDA est aujourd‚Äôhui une r√©f√©rence en mati√®re de **calcul haute performance (HPC)** et est utilis√© dans des domaines vari√©s comme la **science des donn√©es, l‚Äôintelligence artificielle, la simulation physique et la vision par ordinateur**.\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #f17c12; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "## <div style=\"text-align:left; border-radius:6px; padding:px; color:white; margin:5px 0; font-size:70%; font-family:Arial, sans-serif; background-color: #f17c12;\"><b>1.2 üîπ Numba : Un Compilateur Just-In-Time (JIT) pour Python </b></div> \n",
    "\n",
    "\n",
    "\n",
    "[**Numba**](http://numba.pydata.org/) est un **compilateur Just-In-Time (JIT)** pour **Python**, con√ßu pour acc√©l√©rer les fonctions Python orient√©es **calcul num√©rique**. Il offre une interface simple permettant d'am√©liorer consid√©rablement les performances d‚Äôex√©cution, en **rempla√ßant l‚Äôinterpr√©teur Python standard par du code machine optimis√©**.\n",
    "\n",
    "Numba permet d‚Äôacc√©l√©rer les fonctions Python de deux mani√®res :\n",
    "- **Sur CPU** : En g√©n√©rant du code natif optimis√© pour l‚Äôarchitecture du processeur.\n",
    "- **Sur GPU NVIDIA** : En exploitant CUDA pour ex√©cuter du code massivement parall√®le sur le GPU.\n",
    "\n",
    "### üîπ Concepts de Numba :\n",
    "\n",
    "- **Compilateur de fonctions** : Numba compile uniquement des **fonctions Python**, et non des applications enti√®res ni des parties de fonctions. Il ne remplace pas l‚Äôinterpr√©teur Python, mais agit comme un module Python qui transforme une fonction en une version (g√©n√©ralement) plus rapide.\n",
    "\n",
    "- **Sp√©cialisation par type** : Numba acc√©l√®re l‚Äôex√©cution en g√©n√©rant une **impl√©mentation optimis√©e** pour les **types de donn√©es sp√©cifiques** utilis√©s. Contrairement √† Python, qui g√®re des types g√©n√©riques (et donc plus lents), Numba g√©n√®re un code hautement optimis√© pour chaque ensemble de types rencontr√©s.\n",
    "\n",
    "- **Compilation Just-In-Time (JIT)** : Numba traduit les fonctions **au moment de leur premi√®re ex√©cution**, garantissant ainsi une adaptation aux types d‚Äôarguments utilis√©s. Cette approche permet une utilisation interactive dans un **notebook Jupyter**, tout comme dans une application classique.\n",
    "\n",
    "- **Focalis√© sur le calcul num√©rique** : Numba est principalement optimis√© pour les types de donn√©es **num√©riques** (`int`, `float`, `complex`). Le support des cha√Ænes de caract√®res est **tr√®s limit√©**, et leur utilisation sur GPU n‚Äôest pas recommand√©e. Pour tirer le meilleur parti de Numba, il est conseill√© d‚Äôutiliser des **tableaux NumPy**.\n",
    "\n",
    "üöÄ **En r√©sum√©, gr√¢ce √† son int√©gration fluide avec **NumPy**, Numba est un outil puissant pour acc√©l√©rer les calculs scientifiques en Python sans n√©cessiter de programmation en C/C++ ou CUDA.**\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### <img src=\"https://img.icons8.com/ios-filled/20/1e90ff/info--v1.png\" style=\"vertical-align:middle;\"/> üéØ Objectifs de TP\n",
    "\n",
    "\n",
    "L'objectif de ce TP est d‚Äôexplorer les techniques fondamentales permettant d‚Äôacc√©l√©rer les applications Python sur GPU en utilisant Numba. √Ä la fin de ce TP, vous serez capable de :\n",
    "\n",
    "- Utiliser Numba pour compiler des fonctions Python sur le CPU.\n",
    "- Comprendre comment Numba compile les fonctions Python.\n",
    "- Acc√©l√©rer sur GPU les **ufuncs NumPy**.\n",
    "- Acc√©l√©rer sur GPU des fonctions vectoris√©es √©crites √† la main.\n",
    "- Optimiser les transferts de donn√©es entre l‚Äôh√¥te (CPU) et le p√©riph√©rique (GPU).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:8px; color:white; margin:10px 0; font-size:100%; font-family:Arial, sans-serif; background-color:#4682b4;\"><b>üîç 2. üöÄ Premiers pas : Compilation pour le CPU </b></div>\n",
    "\n",
    "Numba peut √™tre utilis√© pour optimiser du code aussi bien pour un **CPU** que pour un **GPU**. Avant d‚Äôaborder l‚Äôacc√©l√©ration GPU, nous allons commencer par √©crire notre premi√®re fonction Numba et la compiler pour le **CPU**. Cela nous permettra de nous familiariser avec la syntaxe de Numba et, un peu plus tard, de comparer les performances entre un code optimis√© pour le CPU et un code acc√©l√©r√© sur GPU.\n",
    "\n",
    "Le compilateur Numba s'active g√©n√©ralement en appliquant un [**d√©corateur de fonction**](https://en.wikipedia.org/wiki/Python_syntax_and_semantics#Decorators) √† une fonction Python. Les d√©corateurs sont des modificateurs de fonction qui transforment les fonctions Python qu‚Äôils d√©corent, en utilisant une syntaxe tr√®s simple. \n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "üîç Ici, nous allons utiliser le d√©corateur de compilation CPU de Numba : **`@jit`**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import math\n",
    "\n",
    "# This is the function decorator syntax and is equivalent to `hypot = jit(hypot)`.\n",
    "# The Numba compiler is just a function you can call whenever you want!\n",
    "@jit\n",
    "def hypot(x, y):\n",
    "    # Implementation from https://en.wikipedia.org/wiki/Hypot\n",
    "    x = abs(x);\n",
    "    y = abs(y);\n",
    "    t = min(x, y);\n",
    "    x = max(x, y);\n",
    "    t = t / x;\n",
    "    return x * math.sqrt(1+t*t)\n",
    "\n",
    "hypot(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üîç D√©tails sur l'ex√©cution de `hypot` avec Numba\n",
    "\n",
    "Nous allons explorer plus en d√©tail ce qui se passe lorsqu'on appelle `hypot`, mais pour l'instant, retenez que **lors du premier appel √† `hypot`**, le compilateur Numba est d√©clench√© et **g√©n√®re une version optimis√©e en code machine** pour les entr√©es de type `float`.\n",
    "\n",
    "Numba conserve √©galement l'impl√©mentation Python originale de la fonction dans l'attribut `.py_func`, ce qui nous permet d'appeler la version Python d'origine afin de v√©rifier que nous obtenons le m√™me r√©sultat :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypot.py_func(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### ‚è±Ô∏è √âvaluation des performances\n",
    "\n",
    "Une partie essentielle de l'utilisation de Numba est la **mesure des performances** de votre nouveau code. Voyons si nous avons r√©ellement acc√©l√©r√© l'ex√©cution.\n",
    "\n",
    "La mani√®re la plus simple de mesurer les performances dans un **notebook Jupyter**, comme celui utilis√© dans cette session, est d'utiliser la fonction  [`%timeit`](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-timeit). \n",
    "\n",
    "Commen√ßons par mesurer la vitesse de la version originale en Python :\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit hypot.py_func(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "La fonction  `%timeit` ex√©cute l'instruction plusieurs fois afin d'obtenir une **estimation pr√©cise du temps d'ex√©cution**.  \n",
    "\n",
    "Par d√©faut, `%timeit` retourne **le meilleur temps mesur√©**, ce qui permet de r√©duire l'impact d'√©ventuels √©v√©nements al√©atoires en arri√®re-plan sur les mesures.  \n",
    "\n",
    "De plus, la **meilleure ex√©cution sur 3 essais** garantit que le temps de compilation lors du premier appel n'influence pas les r√©sultats finaux.\n",
    "\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit hypot(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "Numba a fait du bon travail avec cette fonction. Elle est **clairement plus rapide** que la version purement Python.  \n",
    "\n",
    "Cependant, la fonction `hypot` existe d√©j√† dans le module standard de Python. Voyons comment elle se compare en termes de performance :\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit math.hypot(3.0, 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "La fonction int√©gr√©e de Python est **encore plus rapide** que celle optimis√©e avec Numba !  \n",
    "\n",
    "Cela s'explique par le fait que Numba introduit un **l√©ger surco√ªt √† chaque appel de fonction**, ce qui peut √™tre plus important que celui de Python lui-m√™me. Les **fonctions extr√™mement rapides** (comme celle-ci) peuvent √™tre **p√©nalis√©es** par cet overhead.  \n",
    "\n",
    "üîπ **Remarque importante** : Si une fonction Numba appelle une autre fonction Numba, le surco√ªt est **tr√®s faible**, voire **nul** si le compilateur d√©cide d'**inliner** la fonction dans l'autre.  \n",
    "\n",
    "üìå **Conclusion** : **Toujours mesurer les performances** de vos fonctions pour **v√©rifier le gain r√©el** en vitesse !\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### **üèãÔ∏è‚Äç‚ôÇÔ∏è  Consigne  : Compiler une fonction pour le CPU avec Numba**\n",
    "\n",
    "La fonction ci-dessous utilise la **[M√©thode de Monte-Carlo pour estimer Pi](https://academo.org/demos/estimating-pi-monte-carlo/)** (extrait de la [page officielle de Numba](http://numba.pydata.org/)).  \n",
    "\n",
    "üìå La fonction est **d√©j√† fonctionnelle**, donc inutile de se soucier des d√©tails math√©matiques.\n",
    "\n",
    "üîπ **Votre t√¢che** : Compl√©tez les deux sections marqu√©es `TODO` afin de **compiler `monte_carlo_pi` avec Numba** avant d'ex√©cuter les cellules suivantes.\n",
    "\n",
    "Les cellules suivantes permettront de :\n",
    "\n",
    "1Ô∏è‚É£ **V√©rifier que la version compil√©e donne le m√™me r√©sultat** que la version Python d'origine.  \n",
    "2Ô∏è‚É£ **Mesurer les performances de la version non compil√©e**.  \n",
    "3Ô∏è‚É£ **Mesurer les performances de la version compil√©e avec Numba**.  \n",
    "\n",
    "\n",
    "</div></div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nsamples = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Import Numba's just-in-time compiler function\n",
    "import random\n",
    "\n",
    "# TODO: Use the Numba compiler to compile this function\n",
    "\n",
    "def monte_carlo_pi(nsamples):\n",
    "    acc = 0\n",
    "    for i in range(nsamples):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use numpy's `testing` library to confirm compiled and uncompiled versions run the same\n",
    "from numpy import testing\n",
    "\n",
    "# This assertion will fail until you successfully complete the exercise one cell above\n",
    "testing.assert_almost_equal(monte_carlo_pi(nsamples), monte_carlo_pi.py_func(nsamples), decimal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit monte_carlo_pi(nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit monte_carlo_pi.py_func(nsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### ‚öôÔ∏è Comment fonctionne Numba ?\n",
    "\n",
    "Lorsque nous avons appel√© notre fonction `hypot` d√©cor√©e avec Numba pour la premi√®re fois, le processus suivant a √©t√© initi√©. L'image ci-dessous illustre le processus de compilation d√©clench√© par Numba lorsque vous utilisez un d√©corateur comme `@jit` :\n",
    "\n",
    "\n",
    "![Numba Flowchart](./numba_flowchart.png \"The compilation process\")\n",
    "\n",
    "\n",
    " **üõ†Ô∏è Le processus de compilation avec Numba**\n",
    "\n",
    "\n",
    "1. **Python Function** : La fonction Python est d√©finie normalement.\n",
    "2. **Bytecode Analysis** : Le code bytecode Python est analys√© pour en extraire la logique.\n",
    "3. **Numba IR (Intermediate Representation)** : Une repr√©sentation interm√©diaire sp√©cifique √† Numba est g√©n√©r√©e.\n",
    "4. **Type Inference** : Les types des arguments de la fonction sont inf√©r√©s lors de l'appel pour g√©n√©rer du code sp√©cialis√©.\n",
    "5. **Rewrite IR** : Le code interm√©diaire est r√©√©crit et optimis√©.\n",
    "6. **Lowering** : La repr√©sentation interm√©diaire est traduite en instructions de bas niveau (LLVM IR).\n",
    "7. **LLVM/NVVM JIT** : Le code est compil√© Just-In-Time par LLVM (ou NVVM pour CUDA).\n",
    "8. **Machine Code** : Le code machine est g√©n√©r√© et peut √™tre ex√©cut√© directement.\n",
    "9. **Cache** : Le code compil√© est mis en cache pour les appels futurs.\n",
    "10. **Execute!** : La fonction compil√©e est ex√©cut√©e.\n",
    "\n",
    "Numba permet ainsi de transformer une fonction Python ordinaire en une version optimis√©e, capable de s'ex√©cuter sur CPU ou GPU avec des performances bien meilleures.\n",
    "\n",
    "Nous pouvons observer le **r√©sultat de l'inf√©rence de types** en utilisant la m√©thode `.inspect_types()`, qui affiche une version annot√©e du code source.\n",
    "\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hypot.inspect_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üìù Remarque sur les types de donn√©es dans Numba\n",
    "\n",
    "Les noms des types dans Numba refl√®tent g√©n√©ralement ceux de **[NumPy](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html)**. Par exemple :\n",
    "\n",
    "- Un `float` en Python correspond √† un `float64`.\n",
    "  \n",
    "### ‚ö†Ô∏è Importance des types de donn√©es en code GPU\n",
    "Dans le code GPU, il peut √™tre important de pr√™ter attention aux types de donn√©es car les performances des calculs en `float32` et `float64` peuvent varier **consid√©rablement** selon le GPU.\n",
    "\n",
    "- Si votre algorithme peut produire des r√©sultats corrects avec des `float32`, il est **recommand√© d'utiliser ce type de donn√©es**, car :\n",
    "  - Le passage √† `float64` peut entra√Æner une **diminution importante des performances**.\n",
    "  - Certains GPU CUDA sont optimis√©s pour les calculs en `float32`, rendant ces derniers beaucoup plus rapides.\n",
    "\n",
    "### üöÄ Bonne pratique :\n",
    "**Privil√©giez `float32` si possible** pour maximiser les performances tout en garantissant la pr√©cision n√©cessaire √† vos calculs.\n",
    "\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "### üö¶ Modes Object et nopython\n",
    "\n",
    "Numba ne peut pas compiler tout le code Python. Certaines fonctions n'ont pas encore d'√©quivalent traduit par Numba, et certains types Python ne peuvent pas √™tre compil√©s efficacement (du moins pour l'instant).  Par exemple, **Numba ne prend pas en charge les dictionnaires** (√† la date de r√©daction de ce document).  \n",
    "\n",
    "Essayons de compiler ce morceau de code Python avec Numba :\n",
    "</div></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def cannot_compile(x):\n",
    "    return x['key']\n",
    "\n",
    "cannot_compile(dict(key='value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "√âtant donn√© ce qui a √©t√© dit, vous pourriez √™tre surpris que la cellule pr√©c√©dente se soit ex√©cut√©e sans aucun probl√®me. Cela s'explique par le fait qu'en l'absence de type-sp√©cialisation, **Numba bascule par d√©faut dans un mode appel√© \"object mode\"**.  \n",
    "\n",
    "Dans ce mode, aucune optimisation via type-sp√©cialisation n'est effectu√©e. Bien que ce mode existe pour permettre d'autres fonctionnalit√©s de Numba, il est souvent pr√©f√©rable que Numba vous signale une erreur si l'inf√©rence de types √©choue.\n",
    "\n",
    "### üîπ Forcer le mode `nopython`\n",
    "Pour obliger Numba √† √©chouer lorsque l'inf√©rence de types ne fonctionne pas, vous pouvez activer explicitement le **mode \"nopython\"** en passant l'argument `nopython=True` au d√©corateur :\n",
    "\n",
    "```python\n",
    "@jit(nopython=True)\n",
    "def my_function(...):\n",
    "    ...\n",
    "```\n",
    "Le mode nopython garantit que votre code est enti√®rement optimis√© et ne tombe pas en mode interpr√©t√©.\n",
    "\n",
    "\n",
    "</div></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def cannot_compile(x):\n",
    "    return x['key']\n",
    "\n",
    "cannot_compile(dict(key='value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "Maintenant, une exception est lev√©e lorsque Numba essaie de compiler la fonction. Si vous faites d√©filer jusqu'√† la fin du message d'erreur, vous verrez une description du probl√®me sous-jacent :\n",
    "    \n",
    "    ‚Ä¢ argument 0: cannot determine Numba type of <class ‚Äòdict‚Äô>\n",
    "\n",
    "### üîπ Mode `nopython` : Bonne pratique recommand√©e\n",
    "L'utilisation du mode **`nopython`** est la **meilleure pratique recommand√©e** pour utiliser le d√©corateur `jit`, car elle garantit les meilleures performances en √©liminant le mode interpr√©t√©.\n",
    "\n",
    "### üîπ Simplification avec `njit`\n",
    "Numba propose un autre d√©corateur, **`njit`**, qui est un alias pour **`jit(nopython=True)`**. Cela rend le code plus concis et garantit que Numba fonctionne toujours en mode `nopython` :\n",
    "\n",
    "```python\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def my_function(...):\n",
    "    ...\n",
    "```\n",
    "Utiliser `njit` est le moyen le plus simple d‚Äôassurer des performances optimales avec Numba.\n",
    "\n",
    "### üí° Ressource :\n",
    "\n",
    "Pour une liste exhaustive des fonctionnalit√©s Python prises en charge par Numba, veuillez consulter **[la documentation officielle de Numba](https://numba.pydata.org/numba-doc/dev/reference/pysupported.html)**.\n",
    "\n",
    "</div></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def cannot_compile(x):\n",
    "    return x['key']\n",
    "\n",
    "cannot_compile(dict(key='value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:8px; color:white; margin:10px 0; font-size:100%; font-family:Arial, sans-serif; background-color:#4682b4;\"><b>üîç 2. üöÄ Numba pour le GPU avec les fonctions universelles (ufuncs) de NumPy </b></div>\n",
    "\n",
    "\n",
    "Nous allons commencer notre exploration de la programmation GPU avec Numba en apprenant √† compiler les **[fonctions universelles de NumPy (ou ufuncs)](https://docs.scipy.org/doc/numpy-1.15.1/reference/ufuncs.html)** pour le GPU.\n",
    "\n",
    "\n",
    "La chose la plus importante √† comprendre √† propos de la programmation GPU, au d√©but, est que le mat√©riel GPU est con√ßu pour le **parall√©lisme des donn√©es**. Le d√©bit maximal est atteint lorsque le GPU effectue les **m√™mes op√©rations sur de nombreux √©l√©ments simultan√©ment**.\n",
    "\n",
    "Les fonctions universelles de NumPy (ufuncs), qui appliquent la m√™me op√©ration √† chaque √©l√©ment d‚Äôun tableau NumPy, sont **naturellement parall√®les**, ce qui en fait un excellent choix pour la programmation GPU.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "### üîç Rappel sur les fonctions universelles (ufuncs) de NumPy\n",
    "\n",
    "\n",
    "Si, apr√®s cette introduction, vous ne vous sentez pas √† l‚Äôaise avec les m√©canismes de base de NumPy pour la **cr√©ation de tableaux et l‚Äôutilisation des ufuncs**, il est recommand√© de suivre le **[tutoriel rapide sur NumPy](https://docs.scipy.org/doc/numpy/user/quickstart.html)**.\n",
    "\n",
    "### üìå Qu'est-ce qu'une ufunc ?\n",
    "NumPy introduit le concept de **fonctions universelles (\"ufuncs\")**, qui sont des fonctions capables de :\n",
    "- Manipuler des tableaux NumPy de diff√©rentes dimensions.\n",
    "- Effectuer des op√©rations **√©l√©ment par √©l√©ment** sur les donn√©es.\n",
    "- Accepter aussi bien des **scalaires** que des **tableaux**.\n",
    "\n",
    "\n",
    "Pour illustrer le fonctionnement de base des ufuncs, nous allons utiliser la fonction universelle `add` de NumPy :\n",
    "\n",
    "\n",
    "</div></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([10, 20, 30, 40])\n",
    "\n",
    "np.add(a, b) # Returns a new NumPy array resulting from adding every element in `a` to every element in `b`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "Les **ufuncs** peuvent √©galement combiner des **scalaires** avec des **tableaux**.  \n",
    "\n",
    "\n",
    "</div></div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add(a, 100) # Returns a new NumPy array resulting from adding 100 to every element in `a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üìå Diffusion automatique des dimensions (*Broadcasting*)\n",
    "\n",
    "Les tableaux de **dimensions diff√©rentes mais compatibles** peuvent √™tre combin√©s gr√¢ce √† une technique appel√©e **[*broadcasting*](https://docs.scipy.org/doc/numpy-1.15.0/user/basics.broadcasting.html)**.  \n",
    "\n",
    "Dans ce processus, le tableau ayant la **plus petite dimension** est **r√©pliqu√© automatiquement** pour correspondre √† la dimension du tableau le plus grand, permettant ainsi d'effectuer des op√©rations sans boucle explicite.\n",
    "\n",
    "\n",
    "\n",
    "### üìö Ressources utiles :\n",
    "\n",
    "Ces fonctions NumPy seront utilis√©es plusieurs fois au cours de cette formation :\n",
    "\n",
    "- [`numpy.arange`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.arange.html) : G√©n√®re des s√©quences num√©riques.\n",
    "- [`numpy.ndarray.reshape`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.ndarray.reshape.html) : Reformatage de tableaux NumPy.\n",
    "\n",
    "\n",
    "Le broadcasting est une technique essentielle pour optimiser les calculs et am√©liorer les performances des op√©rations vectoris√©es, notamment sur GPU avec Numba. üöÄ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div></div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = np.arange(4*4).reshape((4,4))\n",
    "print('c:', c)\n",
    "\n",
    "np.add(b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üöÄ Cr√©ation de ufuncs pour le GPU\n",
    "\n",
    "Numba permet de cr√©er des **ufuncs compil√©es**, un processus qui, sans Numba, n√©cessite g√©n√©ralement d'√©crire du code en C.  \n",
    "\n",
    "Avec Numba, il suffit :\n",
    "1. D'impl√©menter une **fonction scalaire** qui sera appliqu√©e √† chaque √©l√©ment des entr√©es.\n",
    "2. De la d√©corer avec `@vectorize`.\n",
    "\n",
    "Numba s‚Äôoccupe ensuite de **g√©rer automatiquement les r√®gles de diffusion (*broadcasting*)**.\n",
    "\n",
    "Si vous √™tes familier avec [`numpy.vectorize`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.vectorize.html), le d√©corateur `vectorize` de Numba vous semblera tr√®s similaire, mais avec **une acc√©l√©ration notable gr√¢ce √† la compilation JIT**. \n",
    "\n",
    "\n",
    "Dans ce premier exemple, nous allons utiliser le d√©corateur `@vectorize` pour **compiler et optimiser une ufunc pour le CPU**. üöÄ\n",
    "</div></div>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize\n",
    "def add_ten(num):\n",
    "    return num + 10 # This scalar operation will be performed on each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nums = np.arange(10)\n",
    "add_ten(nums) # pass the whole array into the ufunc, it performs the operation on each element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "Nous allons g√©n√©rer une **ufunc optimis√©e pour le GPU avec CUDA** en utilisant une **signature de type explicite** et en d√©finissant l‚Äôattribut `target`.  \n",
    "\n",
    "### üìå D√©finition de la signature de type :\n",
    "L‚Äôargument de signature de type indique **les types de donn√©es utilis√©s** pour les arguments et la valeur de retour de la ufunc, sous la forme suivante :\n",
    "```python\n",
    "'return_value_type(argument1_value_type, argument2_value_type, ...)'\n",
    "```\n",
    "\n",
    "Pour plus d‚Äôinformations, consultez la documentation Numba :\n",
    "\n",
    "- üîó [Types disponibles](https://numba.pydata.org/numba-doc/dev/reference/types.html)\n",
    "- üîó [√âcriture de ufuncs avec plusieurs signatures](https://numba.pydata.org/numba-doc/dev/user/vectorize.html)\n",
    "\n",
    "### ‚ú® Exemple : Compilation d‚Äôune ufunc pour le GPU avec CUDA\n",
    "\n",
    "L‚Äôexemple ci-dessous montre une ufunc qui sera compil√©e pour un p√©riph√©rique GPU compatible CUDA. Elle prend en entr√©e deux valeurs int64 et retourne √©galement un int64 :\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize(['int64(int64, int64)'], target='cuda') # Type signature and target are required for the GPU\n",
    "def add_ufunc(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üîç Explication de l'exemple :\n",
    "\n",
    "- La fonction `add_ufunc` est **vectoris√©e** pour une **ex√©cution parall√®le sur GPU**.\n",
    "- La signature **`int64(int64, int64)`** sp√©cifie que les **entr√©es et la sortie** sont de type `int64`.\n",
    "- L‚Äôattribut **`target='cuda'`** indique que la fonction doit √™tre **compil√©e pour CUDA** et ex√©cut√©e sur un **GPU**.\n",
    "Avec cette approche, Numba g√©n√®re automatiquement du code optimis√© pour le GPU, sans n√©cessiter d‚Äô√©criture en CUDA natif !\n",
    "</div></div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_ufunc(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "Pour un simple appel de fonction, **beaucoup de choses viennent de se produire !** üöÄ  \n",
    "\n",
    "Numba a automatiquement r√©alis√© les √©tapes suivantes :  \n",
    "\n",
    "- üõ† **Compilation d‚Äôun noyau CUDA** pour ex√©cuter l‚Äôop√©ration ufunc en parall√®le sur tous les √©l√©ments d'entr√©e.  \n",
    "- üì¶ **Allocation de m√©moire sur le GPU** pour les entr√©es et la sortie.  \n",
    "- ‚¨ÜÔ∏è **Copie des donn√©es d‚Äôentr√©e vers le GPU**.  \n",
    "- ‚ö° **Ex√©cution du noyau CUDA** avec les dimensions adapt√©es aux tailles des entr√©es.  \n",
    "- ‚¨áÔ∏è **Copie du r√©sultat du GPU vers le CPU**.  \n",
    "- üì§ **Renvoi du r√©sultat sous forme d‚Äôun tableau NumPy sur l‚Äôh√¥te (CPU).**  \n",
    "\n",
    "Par rapport √† une impl√©mentation en **C/CUDA natif**, cette approche est **beaucoup plus concise** et √©vite la gestion manuelle des ressources GPU.  \n",
    "\n",
    "#### üöÄ Quelle est la vitesse de notre simple exemple sur GPU ? Voyons cela ! ‚è±\n",
    "\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit np.add(b, c)   # NumPy on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit add_ufunc(b, c) # Numba on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üöÄ Pourquoi notre exemple est-il plus lent sur le GPU ? \n",
    "\n",
    "üò≤ **Le GPU est beaucoup plus lent que le CPU ??**  \n",
    "\n",
    "C‚Äôest un comportement **pr√©visible** car nous avons **d√©lib√©r√©ment** mal utilis√© le GPU dans cet exemple.  \n",
    "\n",
    "Comprendre **pourquoi** le GPU est mal exploit√© ici nous aidera √† identifier **quels types de probl√®mes sont adapt√©s au calcul GPU** et **quels calculs restent plus efficaces sur le CPU**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ùå **Mauvaises pratiques dans notre exemple :**\n",
    "\n",
    "1Ô∏è‚É£ **Nos entr√©es sont trop petites**  \n",
    "   - Le GPU excelle en ex√©cutant **des milliers de calculs en parall√®le**.  \n",
    "   - Ici, nos tableaux contiennent **seulement 4 ou 16 entiers**, ce qui est **insuffisant pour saturer le GPU**.  \n",
    "\n",
    "2Ô∏è‚É£ **Notre calcul est trop simple**  \n",
    "   - L'envoi d'un calcul vers le GPU introduit un **co√ªt fixe important**.  \n",
    "   - Si le calcul est trop rapide (faible **intensit√© arithm√©tique**), le **temps d‚Äôattente** pour les transferts de donn√©es **domine** le gain de parall√©lisation.  \n",
    "\n",
    "3Ô∏è‚É£ **Nous copions inutilement les donn√©es entre CPU et GPU**  \n",
    "   - Le transfert m√©moire entre CPU et GPU est **co√ªteux**.  \n",
    "   - **Bonne pratique** : **Garder les donn√©es sur le GPU** et **encha√Æner plusieurs op√©rations** avant de les r√©cup√©rer.  \n",
    "\n",
    "4Ô∏è‚É£ **Nous utilisons des types de donn√©es trop volumineux**  \n",
    "   - L‚Äôexemple utilise **`int64`**, mais **un `int32` suffirait**.  \n",
    "   - Le co√ªt en performance des types **`float64`** sur le GPU peut √™tre **√©norme** :\n",
    "     - **2√ó plus lent** (Tesla - Pascal)\n",
    "     - **Jusqu‚Äô√† 24√ó plus lent** (GeForce - Maxwell)\n",
    "   - **Bonne pratique** : Utiliser **`float32`** si la pr√©cision est suffisante.  \n",
    "     - ‚ö†Ô∏è **NumPy utilise `float64` par d√©faut**, pensez √† d√©finir le [`dtype`](https://docs.scipy.org/doc/numpy-1.14.0/reference/arrays.dtypes.html) ou √† utiliser [`ndarray.astype()`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.ndarray.astype.html).\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ **Comment mieux exploiter le GPU ?**  \n",
    "Nous allons maintenant essayer un **exemple plus rapide sur le GPU** en appliquant ces **bonnes pratiques** :\n",
    "- Une **op√©ration avec une plus grande intensit√© arithm√©tique** üßÆ  \n",
    "- Une **taille d'entr√©e bien plus grande** üìä  \n",
    "- L'utilisation d'un **type de donn√©es `float32`** \n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ö†Ô∏è **Attention : certaines op√©rations NumPy ne fonctionnent pas sur le GPU !**\n",
    "Dans l'exemple suivant, nous devrons **remplacer** les fonctions NumPy `pi` et `exp` par leurs √©quivalents du module **`math`**.  \n",
    "\n",
    "üìå Pour plus d‚Äôinformations, consultez **[la documentation Numba](https://numba.pydata.org/numba-doc/latest/reference/numpysupported.html)** sur la prise en charge de NumPy sur GPU.\n",
    "\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math # Note that for the CUDA target, we need to use the scalar functions from the math module, not NumPy\n",
    "\n",
    "SQRT_2PI = np.float32((2*math.pi)**0.5)  # Precompute this constant as a float32.  Numba will inline it at compile time.\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Evaluate the Gaussian a million times!\n",
    "x = np.random.uniform(-3, 3, size=1000000).astype(np.float32)\n",
    "mean = np.float32(0.0)\n",
    "sigma = np.float32(1.0)\n",
    "\n",
    "# Quick test on a single element just to make sure it works\n",
    "gaussian_pdf(x[0], 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats # for definition of gaussian distribution, so we can compare CPU to GPU time\n",
    "norm_pdf = scipy.stats.norm\n",
    "%timeit norm_pdf.pdf(x, loc=mean, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit gaussian_pdf(x, mean, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üöÄ Un gain de performance significatif !\n",
    "\n",
    "Nous avons obtenu **une am√©lioration consid√©rable**, **m√™me en tenant compte du co√ªt des transferts de donn√©es** entre le CPU et le GPU.  \n",
    "\n",
    "Les **ufuncs utilisant des fonctions sp√©ciales** (`exp`, `sin`, `cos`, etc.) sur **de grands ensembles de donn√©es** sont particuli√®rement **efficaces sur GPU**, car ces op√©rations sont massivement parall√©lis√©es.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### **üèãÔ∏è‚Äç‚ôÇÔ∏è  Consigne  :  üïí Comparons avec une optimisation CPU**\n",
    "\n",
    "\n",
    "Pour compl√©ter notre comparaison, d√©finissons et **mesurons le temps d'ex√©cution** de la fonction `gaussian_pdf` lorsqu'elle est optimis√©e par **Numba pour le CPU**.  \n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize\n",
    "def cpu_gaussian_pdf(x, mean, sigma):\n",
    "    '''Compute the value of a Gaussian probability density function at x with given mean and sigma.'''\n",
    "    return math.exp(-0.5 * ((x - mean) / sigma)**2) / (sigma * SQRT_2PI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit cpu_gaussian_pdf(x, mean, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "### ‚ö° Comparaison des performances : CPU vs GPU\n",
    "\n",
    "L‚Äôoptimisation de `gaussian_pdf` avec Numba pour le **CPU** est **beaucoup plus rapide** que la version Python non compil√©e. \n",
    "\n",
    "Cependant, elle reste **nettement plus lente** que l‚Äôex√©cution **acc√©l√©r√©e sur GPU**, qui tire parti du calcul massivement parall√®le pour traiter de **grands ensembles de donn√©es** de mani√®re optimale.  \n",
    "\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### ‚öôÔ∏è Fonctions de p√©riph√©rique CUDA (*CUDA Device Functions*)\n",
    "\n",
    "Les **ufuncs** sont **tr√®s efficaces** lorsqu'il s'agit d'effectuer des **op√©rations √©l√©ment par √©l√©ment**, une t√¢che extr√™mement courante.  \n",
    "\n",
    "Cependant, certains calculs **ne correspondent pas** √† ce mod√®le vectoris√©.  \n",
    "\n",
    "#### üöÄ Compiler des fonctions GPU non vectoris√©es\n",
    "Pour compiler des **fonctions non vectoris√©es** sur le **GPU**, nous utilisons `numba.cuda.jit`.  \n",
    "\n",
    "Dans la prochaine section, nous approfondirons l'utilisation de `numba.cuda.jit`, mais pour l‚Äôinstant, voyons **comment l‚Äôutiliser pour d√©corer une fonction auxiliaire**, qui sera ensuite utilis√©e dans une ufunc acc√©l√©r√©e sur GPU.  Cela permet d'**√©viter de surcharger une seule ufunc** avec toute la logique de calcul.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìå Exemple : Fonction auxiliaire GPU avec `device=True`\n",
    "Dans l'exemple ci-dessous, la fonction `polar_to_cartesian` :\n",
    "- **Ne n√©cessite pas de signature de type** (contrairement aux ufuncs vectoris√©es).\n",
    "- **Prend deux valeurs scalaires** en entr√©e, contrairement aux **ufuncs vectoris√©es** qui manipulent des tableaux NumPy.\n",
    "- **Ne peut √™tre appel√©e que depuis une fonction ex√©cut√©e sur le GPU** gr√¢ce √† `device=True`.\n",
    "\n",
    "üìå L‚Äôargument device=True indique que cette fonction ne peut √™tre appel√©e que depuis un code ex√©cut√© sur le GPU, et non depuis le CPU.\n",
    "\n",
    "Cela permet une meilleure modularit√© en cr√©ant des fonctions r√©utilisables au sein de calculs plus complexes sur le GPU. üöÄ\n",
    "\n",
    "\n",
    "\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def polar_to_cartesian(rho, theta):\n",
    "    x = rho * math.cos(theta)\n",
    "    y = rho * math.sin(theta)\n",
    "    return x, y\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32, float32)'], target='cuda')\n",
    "def polar_distance(rho1, theta1, rho2, theta2):\n",
    "    x1, y1 = polar_to_cartesian(rho1, theta1) # We can use device functions inside our GPU ufuncs\n",
    "    x2, y2 = polar_to_cartesian(rho2, theta2)\n",
    "    \n",
    "    return ((x1 - x2)**2 + (y1 - y2)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "rho1 = np.random.uniform(0.5, 1.5, size=n).astype(np.float32)\n",
    "theta1 = np.random.uniform(-np.pi, np.pi, size=n).astype(np.float32)\n",
    "rho2 = np.random.uniform(0.5, 1.5, size=n).astype(np.float32)\n",
    "theta2 = np.random.uniform(-np.pi, np.pi, size=n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polar_distance(rho1, theta1, rho2, theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üìå **Remarque importante**\n",
    "Le **compilateur CUDA** applique une **inlining agressive** aux **fonctions de p√©riph√©rique (`device=True`)**.  \n",
    "\n",
    "Cela signifie que :\n",
    "- Il n‚Äôy a **g√©n√©ralement aucun surco√ªt** pour les appels de fonction.\n",
    "- Les **tuples retourn√©s** (comme dans `polar_to_cartesian`) **ne sont pas r√©ellement cr√©√©s** en tant qu'objets Python.  \n",
    "  - Ils sont temporairement repr√©sent√©s comme une **structure (`struct`)**.\n",
    "  - Cette structure est ensuite **optimis√©e et supprim√©e** par le compilateur.\n",
    "\n",
    "####  üí° **Conclusion** :\n",
    " L‚Äôutilisation de **fonctions auxiliaires sur GPU** avec `device=True` ne **ralentit pas** l‚Äôex√©cution et permet une meilleure **organisation du code** sans perte de performance. \n",
    "\n",
    "\n",
    "### ‚úÖ Python autoris√© sur le GPU\n",
    "\n",
    "L‚Äôex√©cution de Python sur GPU avec Numba est **plus limit√©e** que sur CPU.  \n",
    "Bien que Numba sur CPU soit d√©j√† restreint, la version GPU impose **encore plus de contraintes**.  \n",
    "\n",
    "#### üîπ Fonctions et structures Python prises en charge :\n",
    "- **Conditions** : `if` / `elif` / `else`\n",
    "- **Boucles** : `while` et `for`\n",
    "- **Op√©rateurs math√©matiques de base**\n",
    "- **Certaines fonctions** des modules `math` et `cmath`\n",
    "- **Tuples**\n",
    "\n",
    "üìå Pour une liste d√©taill√©e des fonctionnalit√©s prises en charge, consultez **[le manuel de Numba](http://numba.pydata.org/numba-doc/latest/cuda/cudapysupported.html)**. \n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üèãÔ∏è‚Äç‚ôÇÔ∏è Exercice : Acc√©l√©rer une fonction sur GPU\n",
    "\n",
    "Nous allons acc√©l√©rer sur **GPU** une fonction de **suppression des valeurs faibles (\"zero suppression\")**.  \n",
    "\n",
    "üìå **Contexte** :  \n",
    "Lors du traitement de **signaux** ou de **formes d'onde**, il est courant de **forcer √† z√©ro** toutes les valeurs dont l'**amplitude absolue** est inf√©rieure √† un certain seuil.  \n",
    "Cela permet de **r√©duire le bruit de faible amplitude** dans les mesures.\n",
    "\n",
    "Voyons d'abord comment **g√©n√©rer des donn√©es d'exemple** pour tester notre fonction :\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This allows us to plot right here in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Hacking up a noisy pulse train\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "n = 100000\n",
    "noise = np.random.normal(size=n) * 3\n",
    "pulses = np.maximum(np.sin(np.arange(n) / (n / 23)) - 0.3, 0.0)\n",
    "waveform = ((pulses * 300) + noise).astype(np.int16)\n",
    "plt.plot(waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üöÄ Acc√©l√©ration GPU de `zero_suppress`\n",
    "\n",
    "Nous allons maintenant **d√©corer la fonction `zero_suppress`** pour qu'elle s'ex√©cute comme une **ufunc vectoris√©e sur un p√©riph√©rique CUDA**.\n",
    "\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### **üèãÔ∏è‚Äç‚ôÇÔ∏è  Consigne  :**\n",
    "\n",
    "- Transformer `zero_suppress` en une **ufunc compatible GPU**.\n",
    "- Exploiter la **parall√©lisation massive** du GPU pour traiter efficacement de grands ensembles de donn√©es.\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "üí° **Astuce** : Utilisez le d√©corateur `@vectorize` avec `target='cuda'` pour que Numba compile la fonction pour **une ex√©cution parall√®le sur le GPU**.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_suppress(waveform_value, threshold):\n",
    "    if waveform_value < threshold:\n",
    "        result = 0\n",
    "    else:\n",
    "        result = waveform_value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will throw an error until you successfully vectorize the `zero_suppress` function above.\n",
    "# The noise on the baseline should disappear when zero_suppress is implemented\n",
    "plt.plot(zero_suppress(waveform, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:8px; color:white; margin:10px 0; font-size:100%; font-family:Arial, sans-serif; background-color:#4682b4;\"><b>üîç 3. üöÄ Gestion de la m√©moire GPU </b></div>\n",
    "\n",
    "\n",
    "Jusqu'√† pr√©sent, nous avons utilis√© des **tableaux NumPy sur le CPU** comme **entr√©es et sorties** de nos fonctions GPU.  \n",
    "Numba a automatiquement **transf√©r√© ces donn√©es vers le GPU**, afin qu'elles puissent √™tre trait√©es.  \n",
    "\n",
    "Cependant, **ce transfert automatique a un co√ªt √©lev√©** :  \n",
    "Apr√®s chaque ex√©cution, **Numba renvoie automatiquement les r√©sultats sur le CPU**, ce qui peut consid√©rablement ralentir le programme.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ö†Ô∏è **Pourquoi minimiser les transferts de donn√©es ?**\n",
    "üìå Le **[Guide des meilleures pratiques CUDA](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html)** recommande :\n",
    "\n",
    "> **Haute priorit√©** : Minimiser les transferts de donn√©es entre l‚Äôh√¥te (CPU) et le p√©riph√©rique (GPU),  \n",
    "> m√™me si cela signifie ex√©cuter certains noyaux sur le GPU qui n‚Äôapportent pas de gain de performance imm√©diat.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ **Solution : Utiliser les CUDA Device Arrays**\n",
    "Une **approche optimis√©e** consiste √† utiliser des **CUDA Device Arrays**, qui :\n",
    "- ‚ùå **Ne sont pas automatiquement copi√©s vers le CPU** apr√®s traitement.\n",
    "- ‚úÖ **Peuvent √™tre r√©utilis√©s** pour d'autres calculs **directement sur le GPU**.\n",
    "- üîÑ **Ne sont transf√©r√©s vers le CPU que lorsque c‚Äôest r√©ellement n√©cessaire**, r√©duisant ainsi le temps d‚Äôex√©cution.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ú® D√©monstration : Cr√©ation d‚Äôune ufunc d‚Äôaddition avec CUDA Device Arrays\n",
    "Voyons comment cr√©er une **ufunc d‚Äôaddition** tout en g√©rant **efficacement la m√©moire GPU**. üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def add_ufunc(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 100000\n",
    "x = np.arange(n).astype(np.float32)\n",
    "y = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit add_ufunc(x, y)  # Baseline performance with host arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üöÄ Transfert des donn√©es du CPU vers le GPU avec `numba.cuda`\n",
    "\n",
    "Le module **`numba.cuda`** propose une fonction permettant de **copier des donn√©es du CPU vers le GPU** et de les stocker sous forme de **CUDA Device Arrays**.  \n",
    "\n",
    "üìå **Remarque importante** :\n",
    "- Lorsque nous affichons une **Device Array**, nous obtenons uniquement **des informations sur l‚Äôobjet**.\n",
    "- Nous **ne voyons pas directement son contenu**, car les donn√©es sont stock√©es **sur le GPU**.\n",
    "- Pour afficher les valeurs, **il faut d'abord les transf√©rer vers le CPU**, ce que nous verrons plus tard.\n",
    "\n",
    "\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "x_device = cuda.to_device(x)\n",
    "y_device = cuda.to_device(y)\n",
    "\n",
    "print(x_device)\n",
    "print(x_device.shape)\n",
    "print(x_device.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "Les **CUDA Device Arrays** peuvent √™tre **pass√©s directement** en argument aux fonctions CUDA, **exactement comme des tableaux NumPy**.  \n",
    "En √©vitant les transferts de m√©moire inutiles, **nous optimisons les performances** et **maximisons l‚Äôefficacit√© du GPU**. \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit add_ufunc(x_device, y_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "√âtant donn√© que `x_device` et `y_device` sont **d√©j√† stock√©s sur le GPU**, notre **benchmark est bien plus rapide**. ‚ö°\n",
    "\n",
    "#### ‚ùå **Probl√®me : allocation et copie inutiles**\n",
    "- Actuellement, une **Device Array de sortie** est **automatiquement allou√©e**.\n",
    "- Apr√®s le calcul, elle est **copi√©e vers le CPU**, **m√™me si nous ne l‚Äôassignons pas √† une variable**.\n",
    "\n",
    "#### ‚úÖ **Solution : cr√©er manuellement le tableau de sortie**\n",
    "Nous pouvons √©viter cette **allocation et copie inutiles** en cr√©ant le tableau de sortie directement sur le **GPU** √† l‚Äôaide de [`numba.cuda.device_array()`](https://numba.pydata.org/numba-doc/dev/cuda-reference/memory.html#numba.cuda.device_array).\n",
    "\n",
    "Cela permet de :\n",
    "- **Contr√¥ler l‚Äôallocation m√©moire** sur le GPU.\n",
    "- **√âviter les transferts de donn√©es inutiles** entre GPU et CPU.\n",
    "- **R√©utiliser le tableau de sortie** pour plusieurs op√©rations GPU avant de le rapatrier sur le CPU.\n",
    "\n",
    "Voyons comment mettre cela en pratique ! üöÄ\n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_device = cuda.device_array(shape=(n,), dtype=np.float32)  # does not initialize the contents, like np.empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "Nous pouvons ensuite utiliser le mot-cl√© sp√©cial **`out`** dans l‚Äô**ufunc** afin de **sp√©cifier un tampon de sortie**.  \n",
    "\n",
    "Cela permet de **contr√¥ler o√π le r√©sultat est stock√©** et **d'√©viter les copies inutiles** entre le GPU et le CPU. \n",
    "\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit add_ufunc(x_device, y_device, out=out_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "L‚Äôappel √† **`add_ufunc`** dans ce cas **ne g√©n√®re aucun transfert de donn√©es** entre l‚Äôh√¥te (**CPU**) et le p√©riph√©rique (**GPU**), ce qui garantit une **ex√©cution ultra-rapide**. üöÄ\n",
    "\n",
    "Si nous avons besoin de r√©cup√©rer une **Device Array** sur le CPU, nous pouvons utiliser la m√©thode **`copy_to_host()`** :\n",
    "\n",
    "\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_host = out_device.copy_to_host()\n",
    "print(out_host[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### ‚öñÔ∏è Comparaison √©quitable des performances \n",
    "\n",
    "Vous pourriez penser que notre **comparaison n'est pas totalement √©quitable**, car nous **n‚Äôavons pas inclus les appels √† `to_device` dans le benchmark** des Device Arrays, alors que les **transferts implicites** sont comptabilis√©s lorsque nous utilisons des tableaux h√¥te (`a` et `b`).  \n",
    " \n",
    "\n",
    "Cependant, notre fonction **`add_func`** n‚Äôest **pas un bon candidat pour l‚Äôacc√©l√©ration GPU**, comme mentionn√© pr√©c√©demment.  \n",
    "L‚Äôobjectif ici √©tait **uniquement de d√©montrer** comment √©liminer **les transferts inutiles** entre le **CPU et le GPU**.\n",
    "\n",
    "#### üìå **Bonne pratique : mesurer l‚Äôimpact des transferts**\n",
    "üîπ **Toujours benchmarker les transferts de donn√©es** pour √©valuer si **l‚Äôacc√©l√©ration GPU est r√©ellement b√©n√©fique**.  \n",
    "üîπ **Dans certains cas, le co√ªt des transferts peut annuler le gain en calcul parall√®le**.  \n",
    "\n",
    "---\n",
    "\n",
    "#### üìö **Gestion avanc√©e de la m√©moire GPU**\n",
    "Numba propose **d‚Äôautres m√©thodes** pour g√©rer la m√©moire et les transferts entre le **CPU et le GPU**.  \n",
    "Consultez la **[documentation officielle](https://numba.pydata.org/numba-doc/dev/cuda/memory.html)** pour d√©couvrir **toutes les options disponibles**. üöÄ\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "\n",
    "### **üèãÔ∏è‚Äç‚ôÇÔ∏è  Consigne  : Optimiser les transferts de m√©moire**\n",
    "\n",
    "√âtant donn√© ces **ufuncs** :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "@vectorize(['float32(float32, float32, float32)'], target='cuda')\n",
    "def make_pulses(i, period, amplitude):\n",
    "    return max(math.sin(i / period) - 0.3, 0.0) * amplitude\n",
    "\n",
    "n = 100000\n",
    "noise = (np.random.normal(size=n) * 3).astype(np.float32)\n",
    "t = np.arange(n, dtype=np.float32)\n",
    "period = n / 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color: #e6f7ff; border-radius:8px; padding:15px; border-left:6px solid #1e90ff; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "### **‚ö° Optimisation : √âviter les transferts de donn√©es inutiles**\n",
    "\n",
    "Actuellement, dans la cellule ci-dessous, un **transfert de donn√©es superflu** a lieu entre le **CPU (h√¥te)** et le **GPU (p√©riph√©rique)** :\n",
    "1. **Apr√®s** l‚Äôappel √† `make_pulses`, les donn√©es sont **renvoy√©es au CPU**.\n",
    "2. **Avant** l‚Äôappel √† `add_ufunc`, elles sont **recopi√©es sur le GPU**.\n",
    "\n",
    "### üìå **Objectif : R√©duire les transferts CPU-GPU**\n",
    "\n",
    "üîπ **Effectuer une seule copie** des donn√©es vers le GPU **avant** `make_pulses`.  \n",
    "üîπ **Garder les donn√©es sur le GPU** jusqu'√† ce que tous les calculs soient termin√©s.  \n",
    "üîπ **Rapatrier les donn√©es vers le CPU** **seulement apr√®s** `add_ufunc`.\n",
    "\n",
    "üí° **Mise √† jour √† effectuer** :\n",
    "- **Utiliser les allocations GPU** (`numba.cuda.device_array`) pour stocker les donn√©es sur le **GPU** entre les appels de fonction.  \n",
    "- **Remplacer les copies interm√©diaires** par une gestion plus efficace de la m√©moire.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pulses = make_pulses(t, period, 100.0)\n",
    "waveform = add_ufunc(pulses, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:8px; color:white; margin:10px 0; font-size:100%; font-family:Arial, sans-serif; background-color:#4682b4;\"><b>üîç 4. ‚ö° Acc√©l√©rer les calculs des r√©seaux neuronaux sur GPU </b></div>\n",
    "\n",
    "Dans cet exercice, vous devrez **mettre en pratique toutes les techniques** apprises jusqu'√† pr√©sent pour **acc√©l√©rer les calculs d‚Äôun r√©seau de neurones sur GPU**. \n",
    "\n",
    "Nous allons **r√©√©crire et optimiser** une version simplifi√©e du code effectuant les calculs n√©cessaires √† la cr√©ation d‚Äôune **couche cach√©e dans un r√©seau de neurones**.  \n",
    "\n",
    "#### üìå **Travail effectu√© par le code :**\n",
    "- **Normalisation** des valeurs en niveaux de gris.\n",
    "- **Application des poids** aux neurones.\n",
    "- **Application d‚Äôune fonction d‚Äôactivation**.\n",
    "\n",
    "#### üéØ **Objectif : Acc√©l√©rer ces calculs avec le GPU**\n",
    "Votre t√¢che consiste √† **d√©placer ces op√©rations sur le GPU** en utilisant les **techniques d‚Äôacc√©l√©ration avec Numba** que vous avez apprises, **tout en garantissant l‚Äôexactitude des calculs**.  \n",
    "\n",
    "üöÄ **Optimisation attendue** :\n",
    "- ‚úÖ Utiliser **les ufuncs et la vectorisation GPU**.\n",
    "- ‚úÖ Minimiser **les transferts CPU-GPU** pour √©viter les ralentissements.\n",
    "- ‚úÖ Exploiter **les CUDA Device Arrays** pour une gestion efficace de la m√©moire.\n",
    "\n",
    "### **üì• Importation des biblioth√®ques et initialisation des valeurs**\n",
    "\n",
    "Avant de commencer, ex√©cutez cette cellule pour **importer les biblioth√®ques n√©cessaires** et **initialiser les valeurs** requises pour l‚Äôexercice.  \n",
    "\n",
    "\n",
    "üöÄ **Ex√©cutez la cellule ci-dessous avant de poursuivre !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You should not modify this cell, it contains imports and initial values needed to do work on either\n",
    "# the CPU or the GPU.\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda, vectorize\n",
    "\n",
    "# Our hidden layer will contain 1M neurons.\n",
    "# When you assess your work below, this value will be automatically set to 100M.\n",
    "n = 1000000\n",
    "\n",
    "greyscales = np.floor(np.random.uniform(0, 255, n).astype(np.float32))\n",
    "weights = np.random.normal(.5, .1, n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "## üöÄ Acc√©l√©ration GPU\n",
    "\n",
    "Dans cette section, vous devrez **modifier chacune des 3 cellules** pour optimiser les calculs sur **GPU** avant d'√©valuer vos r√©sultats.\n",
    "\n",
    "üìå **Instructions :**\n",
    "- **Suivez les commentaires** dans chaque cellule pour savoir o√π apporter des modifications.\n",
    "- **Utilisez les techniques apprises** : `@vectorize`, `@cuda.jit`, `device_array`, etc.\n",
    "- **Optimisez les transferts de m√©moire** entre le **CPU et le GPU**.\n",
    "- **V√©rifiez l‚Äôexactitude des r√©sultats** apr√®s optimisation.\n",
    "\n",
    "üí° **Astuce** : Testez **chaque modification progressivement** pour s‚Äôassurer que les calculs restent corrects.\n",
    "\n",
    "üî• **√Ä vous de jouer !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As you will recall, `numpy.exp` works on the CPU, but, cannot be used in GPU implmentations.\n",
    "# This import will work for the CPU-only boilerplate code provided below, but\n",
    "# you will need to modify this import before your GPU implementation will work.\n",
    "from numpy import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(grayscales):\n",
    "    return grayscales / 255\n",
    "\n",
    "def weigh(values, weights):\n",
    "    return values * weights\n",
    "        \n",
    "def activate(values):\n",
    "    return ( exp(values) - exp(-values) ) / ( exp(values) + exp(-values) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify these 3 previous function calls to run on the GPU.\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_hidden_layer(n, greyscales, weights, exp, normalize, weigh, activate):\n",
    "    \n",
    "    normalized = normalize(greyscales)\n",
    "    weighted = weigh(normalized, weights)\n",
    "    activated = activate(weighted)\n",
    "    \n",
    "    return activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the body of this function to optimize data transfers and therefore speed up performance.\n",
    "# As a constraint, even after you move work to the GPU, make this function return a host array.\n",
    "# Modify the body of this function to optimize data transfers and therefore speed up performance.\n",
    "# As a constraint, even after you move work to the GPU, make this function return a host array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üõ†Ô∏è V√©rifiez votre travail\n",
    "\n",
    "**V√©rifier votre impl√©mentation**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You probably don't need to edit this cell, unless you change the name of any of the values being passed as\n",
    "# arguments to `create_hidden_layer` below.\n",
    "arguments = {\"n\":n,\n",
    "            \"greyscales\": greyscales,\n",
    "            \"weights\": weights,\n",
    "            \"exp\": exp,\n",
    "            \"normalize\": normalize,\n",
    "            \"weigh\": weigh,\n",
    "            \"activate\": activate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit a = create_hidden_layer(**arguments)\n",
    "%timeit b = create_hidden_layer_gpu(**arguments)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:8px; color:white; margin:10px 0; font-size:100%; font-family:Arial, sans-serif; background-color:#4682b4;\"><b>‚úÖ 5. Conslusion</b></div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "√Ä pr√©sent que vous avez termin√© ce TP, vous √™tes capable de :\n",
    "\n",
    "- ‚úÖ Utiliser **Numba** pour compiler des fonctions Python sur le **CPU**.\n",
    "- ‚úÖ Comprendre le processus de compilation des fonctions avec **Numba**.\n",
    "- ‚úÖ **Acc√©l√©rer sur GPU** des **ufuncs NumPy**.\n",
    "- ‚úÖ **Acc√©l√©rer sur GPU** des fonctions vectoris√©es √©crites manuellement.\n",
    "- ‚úÖ Optimiser les **transferts de m√©moire** entre l‚Äôh√¥te **CPU** et le p√©riph√©rique **GPU**.\n",
    "\n",
    "\n",
    "</div></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:8px; color:white; margin:10px 0; font-size:100%; font-family:Arial, sans-serif; background-color:#4682b4;\"><b> üéÅ 6. üìö Annexe : Ufuncs g√©n√©ralis√©es (*Generalized Ufuncs*)</b></div>\n",
    "\n",
    "\n",
    "Les **ufuncs** appliquent une fonction scalaire √† des **entr√©es sous forme de tableaux**, mais que faire si vous voulez appliquer une **fonction sur des tableaux de dimensions inf√©rieures** √† des **tableaux de dimensions sup√©rieures** ? Cela s'appelle une **ufunc g√©n√©ralis√©e** (*generalized ufunc* ou **gufunc**), et cela ouvre un tout nouveau champ d'applications pour les ufuncs.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîπ **Pourquoi les gufuncs sont-elles utiles ?**\n",
    "Les **gufuncs** permettent de :\n",
    "- Diffuser des **fonctions plus complexes** sur des tableaux de dimensions vari√©es.\n",
    "- G√©rer des **mod√®les complexes d'indexation** pour plusieurs entr√©es.\n",
    "- Effectuer des calculs comme la normalisation L2 ou les sommes par lignes sur des tableaux de grandes dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "#### üî∏ **Signature des gufuncs**\n",
    "Contrairement aux ufuncs classiques, les gufuncs n√©cessitent une **signature** (diff√©rente de la signature de type Numba). Cette signature :\n",
    "- D√©crit l'**ordre des index** pour les entr√©es et sorties.\n",
    "- Permet de g√©rer **des op√©rations multidimensionnelles**.\n",
    "\n",
    "‚ÑπÔ∏è **Explication compl√®te des signatures** :\n",
    "- [Docs NumPy sur les gufuncs](https://docs.scipy.org/doc/numpy/reference/c-api.generalized-ufuncs.html)\n",
    "- [Docs Numba sur les gufuncs](http://numba.pydata.org/numba-doc/latest/user/vectorize.html#the-guvectorize-decorator)\n",
    "- [Docs Numba sur les CUDA gufuncs](http://numba.pydata.org/numba-doc/latest/cuda/ufunc.html#generalized-cuda-ufuncs)\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ú® Exemple : Fonction de normalisation\n",
    "Cr√©ons une fonction de normalisation qui :\n",
    "- Accepte un tableau en entr√©e.\n",
    "- Calcule la **norme L2** le long de la derni√®re dimension.\n",
    "\n",
    "#### ‚ö†Ô∏è Remarque :\n",
    "- Les **gufuncs** prennent le tableau de sortie comme **dernier argument**, au lieu de retourner une valeur.\n",
    "- Si la sortie est un scalaire, elle sera repr√©sent√©e comme un tableau d'une dimension inf√©rieure √† celle de l'entr√©e.\n",
    "\n",
    "#### üîç Exemple de r√©sultats :\n",
    "1. **Somme des lignes d'un tableau 2D** : Retourne un tableau 1D.\n",
    "2. **Somme des matrices d'un tableau 3D** : Retourne un tableau 2D.\n",
    "\n",
    "\n",
    "</div></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import guvectorize\n",
    "import math\n",
    "\n",
    "@guvectorize(['(float32[:], float32[:])'], # have to include the output array in the type signature\n",
    "             '(i)->()',                 # map a 1D array to a scalar output\n",
    "             target='cuda')\n",
    "def l2_norm(vec, out):\n",
    "    acc = 0.0\n",
    "    for value in vec:\n",
    "        acc += value**2\n",
    "    out[0] = math.sqrt(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "**üß™ Tester la fonction : Construire des points sur le cercle unit√©**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "angles = np.random.uniform(-np.pi, np.pi, 10)\n",
    "coords = np.stack([np.cos(angles), np.sin(angles)], axis=1)\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "**‚úÖ R√©sultat attendu : La norme L2 est √©gale √† 1.0**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_norm(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height: 5px; background: linear-gradient(to right, #007BFF, #00C3FF); border: none;\">\n",
    "\n",
    "<hr style=\"height: 5px; background: linear-gradient(to right, #007BFF, #00C3FF); border: none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <div style=\"text-align:center; border-radius:15px 50px; padding:15px; color:white; margin:0; font-size:150%; font-family:Pacifico; background-color:#2a6199; overflow:hidden\"><b>  üß†  TP 3.2 -  Calcul Acc√©l√©r√©e avec CUDA Python (NUMBA) </b> \n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:10px; color:white; margin:10px 0; font-size:110%; font-family:Arial, sans-serif; background-color: #4682b4;\"><b>1. Introduction aux Kernels CUDA avec Numba </b></div>\n",
    "\n",
    "\n",
    "Dans cette section, nous approfondirons notre compr√©hension du **mod√®le de programmation CUDA** pour organiser le travail parall√®le. Nous utiliserons ces connaissances pour √©crire des **kernels CUDA personnalis√©s**, des fonctions ex√©cut√©es en parall√®le sur les GPU CUDA.\n",
    "\n",
    "### üéØ **Qu'est-ce qu'un kernel CUDA personnalis√© ?**\n",
    "Un **kernel CUDA** est une fonction qui :\n",
    "- S‚Äôex√©cute directement sur un **GPU CUDA**.\n",
    "- Permet de r√©partir les calculs **massivement parall√®les**.\n",
    "- Offre une flexibilit√© et des performances optimales dans des cas o√π les **ufuncs** ne suffisent pas.\n",
    "\n",
    "### üõ†Ô∏è **Pourquoi utiliser des kernels personnalis√©s ?**\n",
    "Bien que plus complexes √† impl√©menter (par rapport √† un simple d√©corateur `@vectorize`), les kernels personnalis√©s permettent de :\n",
    "- R√©aliser des calculs parall√®les dans des sc√©narios o√π les **ufuncs ne peuvent pas √™tre appliqu√©es**.\n",
    "- Exploiter pleinement la **puissance du GPU** en optimisant l'organisation des threads et blocs.\n",
    "- G√©rer des cas d'utilisation complexes n√©cessitant un contr√¥le total sur les calculs parall√®les.\n",
    "\n",
    "---\n",
    "\n",
    "### üìö **Contenu de cette partie 2 :**\n",
    "- **Organisation du travail parall√®le** avec le mod√®le de programmation CUDA.\n",
    "- **√âcriture et ex√©cution de kernels CUDA personnalis√©s** avec Numba.\n",
    "- Exploration des **meilleures pratiques** pour optimiser les calculs sur GPU.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "üéØ **Objectif final :** Apprendre √† √©crire des kernels CUDA personnalis√©s pour **d√©verrouiller le potentiel maximal du GPU** dans vos applications ! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame('./AC_CUDA_Python_1.pptx', width=640, height=390)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:8px; color:white; margin:10px 0; font-size:100%; font-family:Arial, sans-serif; background-color:#4682b4;\"><b>‚úÖ 2. Premier Kernel CUDA : Addition de Tableaux 1D</b></div>\n",
    "\n",
    "\n",
    "\n",
    "Nous allons commencer par un **exemple simple et concret** en **r√©√©crivant notre fonction d'addition** pour des **tableaux NumPy 1D** sur GPU.\n",
    "\n",
    "#### üîπ **Compilation avec `numba.cuda.jit`**\n",
    "Les **kernels CUDA** sont **compil√©s** √† l'aide du **d√©corateur `numba.cuda.jit`**, qui :\n",
    "- üîπ G√©n√®re un **code machine optimis√© pour le GPU**.\n",
    "- üîπ Ne doit **pas √™tre confondu** avec `numba.jit`, qui est destin√© **√† l‚Äôoptimisation CPU**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üéØ **Objectif**\n",
    "- ‚úÖ Comprendre **comment structurer un kernel CUDA** en Python avec **Numba**.\n",
    "- ‚úÖ Apprendre √† **ex√©cuter un kernel sur le GPU** en d√©finissant une **configuration de threads et de blocs**.\n",
    "- ‚úÖ Poser les bases pour **des kernels plus avanc√©s**, adapt√©s √† des calculs massivement parall√®les.\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Lisez attentivement les commentaires** dans le code, ils expliquent des **concepts essentiels** sur la structure et l‚Äôex√©cution des kernels CUDA ! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "# Note the use of an `out` array. CUDA kernels written with `@cuda.jit` do not return values,\n",
    "# just like their C counterparts. Also, no explicit type signature is required with @cuda.jit\n",
    "@cuda.jit\n",
    "def add_kernel(x, y, out):\n",
    "    \n",
    "    # The actual values of the following CUDA-provided variables for thread and block indices,\n",
    "    # like function parameters, are not known until the kernel is launched.\n",
    "    \n",
    "    # This calculation gives a unique thread index within the entire grid (see the slides above for more)\n",
    "    idx = cuda.grid(1)          # 1 = one dimensional thread grid, returns a single value.\n",
    "                                # This Numba-provided convenience function is equivalent to\n",
    "                                # `cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x`\n",
    "\n",
    "    # This thread will do the work on the data element with the same index as its own\n",
    "    # unique index within the grid.\n",
    "    out[idx] = x[idx] + y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 4096\n",
    "x = np.arange(n).astype(np.int32) # [0...4095] on the host\n",
    "y = np.ones_like(x)               # [1...1] on the host\n",
    "\n",
    "d_x = cuda.to_device(x) # Copy of x on the device\n",
    "d_y = cuda.to_device(y) # Copy of y on the device\n",
    "d_out = cuda.device_array_like(d_x) # Like np.array_like, but for device arrays\n",
    "\n",
    "# Because of how we wrote the kernel above, we need to have a 1 thread to one data element mapping,\n",
    "# therefore we define the number of threads in the grid (128*32) to equal n (4096).\n",
    "threads_per_block = 128\n",
    "blocks_per_grid = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_kernel[blocks_per_grid, threads_per_block](d_x, d_y, d_out)\n",
    "cuda.synchronize()\n",
    "print(d_out.copy_to_host()) # Should be [1...4096]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "## üèãÔ∏è‚Äç‚ôÇÔ∏è Exercice : Modifier le Code et Observer les Effets\n",
    "\n",
    "Exp√©rimentez avec la configuration des threads et des blocs dans le kernel CUDA.  \n",
    "Avant d‚Äôex√©cuter chaque modification, **faites une hypoth√®se** sur son impact sur l'ex√©cution.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Modifications √† tester :**\n",
    "1. üìâ **Diminuer** la variable `threads_per_block`.\n",
    "2. üìâ **Diminuer** la variable `blocks_per_grid`.\n",
    "3. üìà **Augmenter** `threads_per_block` et/ou `blocks_per_grid`.\n",
    "4. ‚ùå **Commenter ou supprimer** l‚Äôappel √† `cuda.synchronize()`.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be modified\n",
    "import numpy as np\n",
    "\n",
    "n = 4096\n",
    "x = np.arange(n).astype(np.int32) # [0...4095] on the host\n",
    "y = np.ones_like(x)               # [1...1] on the host\n",
    "\n",
    "d_x = cuda.to_device(x) # Copy of x on the device\n",
    "d_y = cuda.to_device(y) # Copy of y on the device\n",
    "d_out = cuda.device_array_like(d_x) # Like np.array_like, but for device arrays\n",
    "\n",
    "# Because of how we wrote the kernel above, we need to have a 1 thread to one data element mapping,\n",
    "# therefore we define the number of threads in the grid (128*32) to equal n (4096).\n",
    "threads_per_block = 128\n",
    "blocks_per_grid = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_kernel[blocks_per_grid, threads_per_block](d_x, d_y, d_out)\n",
    "cuda.synchronize()\n",
    "print(d_out.copy_to_host()) # Should be [1...4096]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "### üßê R√©sultats et Explications\n",
    "\n",
    "#### üèóÔ∏è **1 & 2 - R√©duction du nombre total de threads**\n",
    "- **Effet** : Certains √©l√©ments du tableau `d_out` ne seront pas mis √† jour.\n",
    "- **Pourquoi ?** Le kernel est con√ßu pour que **chaque thread traite un √©l√©ment unique**.\n",
    "  - Moins de threads = certains √©l√©ments restent non modifi√©s.\n",
    "  - Si **`threads_per_block` diminue**, des **√©l√©ments r√©partis** dans `d_out` sont manquants.\n",
    "  - Si **`blocks_per_grid` diminue**, les **derniers √©l√©ments** de `d_out` sont ignor√©s.\n",
    "\n",
    "---\n",
    "\n",
    "#### üèóÔ∏è **3 - Augmentation du nombre total de threads**\n",
    "- **Effet** : Peut provoquer des acc√®s m√©moire hors limites (*out of bounds*).\n",
    "- **Pourquoi ?** Le kernel **essaie d‚Äôacc√©der √† des indices de m√©moire inexistants**.\n",
    "  - Actuellement, cette erreur ne s'affichera pas directement.\n",
    "  - Plus tard, nous verrons comment utiliser `cuda-memcheck` pour **d√©tecter ces erreurs**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üèóÔ∏è **4 - Suppression de `cuda.synchronize()`**\n",
    "- **Effet attendu** : Peut-√™tre un affichage incorrect, des calculs incomplets ?\n",
    "- **Effet r√©el** : **Aucun impact**.\n",
    "- **Pourquoi ?** Les **copies de m√©moire entre CPU et GPU impliquent une synchronisation implicite**.\n",
    "  - L‚Äôappel √† `cuda.synchronize()` **n'est pas strictement n√©cessaire** ici.\n",
    "  - Il reste cependant **utile dans d‚Äôautres sc√©narios** pour s‚Äôassurer que les calculs sont bien termin√©s.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Conclusion**\n",
    "- ‚úÖ Ajuster **`threads_per_block` et `blocks_per_grid`** est crucial pour **garantir que tous les √©l√©ments sont trait√©s**.\n",
    "- ‚ö†Ô∏è Augmenter **trop de threads** sans contr√¥le peut entra√Æner **des erreurs d‚Äôacc√®s m√©moire**.\n",
    "- üí° La **synchronisation implicite** via les transferts m√©moire **√©vite le besoin d‚Äôun `cuda.synchronize()` dans ce cas**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üèãÔ∏è‚Äç‚ôÇÔ∏è Exercice : Acc√©l√©rer une Fonction CPU en un Kernel CUDA\n",
    "\n",
    "Nous avons ci-dessous une **fonction scalaire CPU** `square_device`, qui pourrait √™tre utilis√©e comme **ufunc** sur CPU.  \n",
    "Votre mission est de **la transformer en un kernel CUDA** avec le d√©corateur `@cuda.jit`.\n",
    "\n",
    "#### ‚ùì **Pourquoi transformer cette fonction en kernel CUDA ?**\n",
    "‚úÖ Bien que l'on puisse utiliser `@vectorize` pour simplifier cette t√¢che, cet exercice vous permet :\n",
    "- **D'appliquer toutes les notions introduites** sur l‚Äô√©criture et l‚Äôex√©cution d‚Äôun kernel CUDA.\n",
    "- **D'apprendre √† g√©rer la configuration des threads et des blocs**.\n",
    "- **De manipuler la m√©moire GPU** en utilisant **des CUDA device arrays**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üéØ **T√¢ches √† r√©aliser :**\n",
    "1. **Refactoriser** `square_device` pour en faire un **kernel CUDA** :\n",
    "   - ‚úÖ Il doit traiter **un seul √©l√©ment** par thread.\n",
    "   - ‚úÖ Il doit utiliser la **hi√©rarchie des threads** (thread ID global).\n",
    "   \n",
    "2. **Convertir** `d_a` et `d_out` en **CUDA device arrays**.\n",
    "\n",
    "3. **Modifier** les variables `blocks` et `threads` pour avoir une **configuration adapt√©e** √† la taille `n` :\n",
    "   - ‚úÖ D√©finir le **nombre optimal de threads par bloc**.\n",
    "   - ‚úÖ D√©finir **le nombre de blocs n√©cessaires**.\n",
    "\n",
    "4. **Lancer** `square_device` avec une **configuration d‚Äôex√©cution** correcte :\n",
    "   ```python\n",
    "   square_device[blocks, threads](d_a, d_out)\n",
    "\n",
    "‚úÖ Validation de votre solution\n",
    "\t‚Ä¢\tUn test d‚Äôassertion est inclus √† la fin du code.\n",
    "\t‚Ä¢\tTant que l‚Äôimpl√©mentation n‚Äôest pas correcte, le test √©chouera.\n",
    "\t‚Ä¢\tUne fois votre solution fonctionnelle, le test passera avec succ√®s. üéâ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def square_device(a):\n",
    "    return a**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor to be a CUDA kernel doing one thread's work.\n",
    "# Don't forget that when using `@cuda.jit`, you must provide an output array as no value will be returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave the values in this cell fixed for this exercise\n",
    "n = 4096\n",
    "\n",
    "a = np.arange(n)\n",
    "out = a**2 # `out` will only be used for testing below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_a = a                  # TODO make `d_a` a device array\n",
    "d_out = np.zeros_like(a) # TODO: make d_out a device array\n",
    "\n",
    "# TODO: Update the execution configuration for the amount of work needed\n",
    "blocks = 0\n",
    "threads = 0\n",
    "\n",
    "# TODO: Launch as a kernel with an appropriate execution configuration\n",
    "d_out = square_device(d_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import testing\n",
    "testing.assert_almost_equal(d_out, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:8px; color:white; margin:10px 0; font-size:100%; font-family:Arial, sans-serif; background-color:#4682b4;\"><b>‚úÖ 3. G√©rer la Latence et Optimiser la Configuration des Threads CUDA</b></div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### üîπ **Comprendre l'architecture des GPU NVIDIA**\n",
    "Les **GPU NVIDIA compatibles CUDA** sont constitu√©s de plusieurs **Streaming Multiprocessors (SMs)**, chacun contenant :\n",
    "- üí° **Plusieurs c≈ìurs CUDA** pour ex√©cuter les instructions en parall√®le.\n",
    "- üìå **Une m√©moire DRAM attach√©e** pour stocker les donn√©es n√©cessaires.\n",
    "- üîÑ **Une capacit√© √† g√©rer plusieurs blocs de threads simultan√©ment**.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Le concept cl√© : cacher la latence avec des warps**\n",
    "üìå Lorsqu'une instruction prend **plusieurs cycles d'horloge** pour s'ex√©cuter (**expire**), le SM peut continuer d'ex√©cuter d'autres instructions **si des warps sont disponibles**.\n",
    "\n",
    "‚úÖ **Pourquoi est-ce important ?**\n",
    "- Les SMs utilisent **de grands fichiers de registres** qui permettent un **changement de contexte ultra-rapide**.\n",
    "- Un **SM bien occup√©** maximise les performances en **√©vitant les temps morts**.\n",
    "\n",
    "üõ†Ô∏è **Conclusion : Pour utiliser pleinement le GPU, il faut fournir aux SMs un nombre suffisant de warps pr√™ts √† √™tre ex√©cut√©s !**\n",
    "\n",
    "---\n",
    "\n",
    "### üìå **Heuristiques pour choisir la bonne configuration des threads**\n",
    "Il n'existe **pas de configuration unique id√©ale**, mais voici **des r√®gles empiriques** pour bien d√©buter :\n",
    "\n",
    "1Ô∏è‚É£ **Taille d‚Äôun bloc de threads (block size)** :\n",
    "   - ‚úÖ **Un multiple de 32 threads** (taille d‚Äôun warp).\n",
    "   - ‚úÖ En g√©n√©ral entre **128 et 512 threads par bloc**.\n",
    "\n",
    "2Ô∏è‚É£ **Taille de la grille (grid size)** :\n",
    "   - ‚úÖ **Utiliser un nombre de blocs suffisant pour occuper tout le GPU**.\n",
    "   - ‚úÖ **Bon point de d√©part** : lancer **2x √† 4x le nombre de SMs** pr√©sents sur le GPU.\n",
    "   - ‚úÖ En g√©n√©ral, **20 - 100 blocs** est une bonne configuration initiale.\n",
    "\n",
    "3Ô∏è‚É£ **Gestion des tr√®s grandes entr√©es** :\n",
    "   - üìå **√âviter de lancer autant de threads que d‚Äô√©l√©ments d‚Äôentr√©e**.\n",
    "   - üìå Trop de **petits blocs** augmente la **surcharge de lancement des kernels**.\n",
    "   - ‚úÖ **Solution** : Utiliser une **strat√©gie d‚Äôacc√®s optimis√©e** (que nous allons explorer ensuite).\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ **R√©sum√© : Bonnes pratiques pour optimiser un kernel CUDA**\n",
    "‚úîÔ∏è **Utiliser des blocs de threads multiples de 32 (warp size).**  \n",
    "‚úîÔ∏è **Maximiser le nombre de warps actifs pour cacher la latence.**  \n",
    "‚úîÔ∏è **Choisir une grille qui occupe bien tous les SMs.**  \n",
    "‚úîÔ∏è **√âviter un trop grand nombre de petits blocs.**  \n",
    "\n",
    "üí° **Prochaine √©tape** : Explorer **les patterns d‚Äôacc√®s optimis√©s** pour **traiter efficacement de grandes entr√©es** ! üî•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:8px; color:white; margin:10px 0; font-size:100%; font-family:Arial, sans-serif; background-color:#4682b4;\"><b>‚úÖ 4. G√©rer de Tr√®s Grandes Donn√©es avec les Grid Stride Loops</b></div>\n",
    "\n",
    "\n",
    "\n",
    "Lorsqu'on travaille avec **d'√©normes ensembles de donn√©es**, une approche na√Øve consistant √† lancer **un thread par √©l√©ment** devient rapidement inefficace.  \n",
    "\n",
    "### üéØ **Solution : les Grid Stride Loops**\n",
    "Cette technique permet de :\n",
    "- ‚úÖ **Optimiser l‚Äôutilisation des threads CUDA** en leur attribuant **plusieurs √©l√©ments √† traiter**.\n",
    "- ‚úÖ **G√©rer efficacement des datasets de grande taille** en √©vitant d‚Äôallouer un thread unique par √©l√©ment.\n",
    "- ‚úÖ **√âviter les limitations sur le nombre de threads** en r√©utilisant ceux d√©j√† actifs.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå **Comment √ßa fonctionne ?**\n",
    "Un **Grid Stride Loop** permet √† chaque thread de :\n",
    "1Ô∏è‚É£ **Travailler sur plusieurs √©l√©ments de l‚Äôentr√©e**, au lieu d‚Äôun seul.  \n",
    "2Ô∏è‚É£ **Boucler √† travers les indices** en incr√©mentant de **gridDim.x * blockDim.x**.  \n",
    "3Ô∏è‚É£ **Maximiser l‚Äôoccupation du GPU** sans n√©cessiter un nombre excessif de threads.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('./AC_CUDA_Python_2.pptx', 640, 390)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "## Premier Grid Stride Loop : Optimisation du Kernel `add_kernel`\n",
    "\n",
    "Nous allons **r√©√©crire** notre kernel `add_kernel` pour **int√©grer une Grid Stride Loop**.  \n",
    "Cette technique permet d'ex√©cuter le kernel **sur de grands ensembles de donn√©es**, tout en optimisant l'acc√®s m√©moire.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ **Pourquoi utiliser une Grid Stride Loop ?**\n",
    "1Ô∏è‚É£ **√âvolutivit√©** : Permet d‚Äôex√©cuter un kernel **sans contrainte** sur la taille des donn√©es.  \n",
    "2Ô∏è‚É£ **R√©duction des acc√®s m√©moire** : Optimise le **coalescement m√©moire global** (global **memory coalescing**).  \n",
    "3Ô∏è‚É£ **Meilleure utilisation du GPU** : Exploite **au maximum** les threads actifs en leur attribuant **plusieurs √©l√©ments** √† traiter.\n",
    "\n",
    "---\n",
    "\n",
    "### üèóÔ∏è **Comment fonctionne une Grid Stride Loop ?**\n",
    "Un thread CUDA **ne traite plus un seul √©l√©ment**, mais :\n",
    "- üèéÔ∏è **It√®re √† travers plusieurs √©l√©ments** en incr√©mentant de **gridDim.x * blockDim.x**.\n",
    "- üîÑ **Travaille sur les donn√©es en m√©moire globale** de mani√®re optimis√©e.\n",
    "- üöÄ **R√©duit les op√©rations m√©moire inutiles**, am√©liorant ainsi les performances.\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### üèãÔ∏è‚Äç‚ôÇÔ∏è Exercice :\n",
    "\n",
    "‚úÖ Modifier `add_kernel` pour **qu‚Äôil utilise une Grid Stride Loop**.  \n",
    "‚úÖ Tester le nouveau kernel **avec des ensembles de donn√©es de grande taille**.  \n",
    "‚úÖ Observer les **gains de performances** en comparant avec la version pr√©c√©dente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def add_kernel(x, y, out):\n",
    "    \n",
    "\n",
    "    start = cuda.grid(1)\n",
    "    \n",
    "    # This calculation gives the total number of threads in the entire grid\n",
    "    stride = cuda.gridsize(1)   # 1 = one dimensional thread grid, returns a single value.\n",
    "                                # This Numba-provided convenience function is equivalent to\n",
    "                                # `cuda.blockDim.x * cuda.gridDim.x`\n",
    "\n",
    "    # This thread will start work at the data element index equal to that of its own\n",
    "    # unique index in the grid, and then, will stride the number of threads in the grid each\n",
    "    # iteration so long as it has not stepped out of the data's bounds. In this way, each\n",
    "    # thread may work on more than one data element, and together, all threads will work on\n",
    "    # every data element.\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        # Assuming x and y inputs are same length\n",
    "        out[i] = x[i] + y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 100000 # This is far more elements than threads in our grid\n",
    "x = np.arange(n).astype(np.int32)\n",
    "y = np.ones_like(x)\n",
    "\n",
    "d_x = cuda.to_device(x)\n",
    "d_y = cuda.to_device(y)\n",
    "d_out = cuda.device_array_like(d_x)\n",
    "\n",
    "threads_per_block = 128\n",
    "blocks_per_grid = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_kernel[blocks_per_grid, threads_per_block](d_x, d_y, d_out)\n",
    "print(d_out.copy_to_host()) # Remember, memory copy carries implicit synchronization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### üèãÔ∏è‚Äç‚ôÇÔ∏è Exercice : üìå **Impl√©menter une Grid Stride Loop**\n",
    "\n",
    "Nous allons **refactoriser** la fonction scalaire CPU `hypot_stride` pour la **transformer en un kernel CUDA** utilisant une **Grid Stride Loop**.\n",
    "\n",
    "1Ô∏è‚É£ **Transformer la fonction** en un kernel CUDA (`@cuda.jit`).  \n",
    "2Ô∏è‚É£ **D√©terminer l‚ÄôID global du thread** pour acc√©der aux donn√©es.  \n",
    "3Ô∏è‚É£ **Utiliser une Grid Stride Loop** :\n",
    "   - üìå Le thread doit **it√©rer** sur plusieurs √©l√©ments avec un pas de `gridDim.x * blockDim.x`.  \n",
    "   - üìå **Optimiser l'acc√®s m√©moire** pour tirer parti du **coalescement m√©moire global**.\n",
    "  \n",
    "4Ô∏è‚É£ **Configurer correctement** les `blocks` et `threads` pour tester la performance du kernel.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import hypot\n",
    "\n",
    "def hypot_stride(a, b, c):\n",
    "    c = hypot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tap your solution here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You do not need to modify the contents in this cell\n",
    "n = 1000000\n",
    "a = np.random.uniform(-12, 12, n).astype(np.float32)\n",
    "b = np.random.uniform(-12, 12, n).astype(np.float32)\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "d_c = cuda.device_array_like(d_b)\n",
    "\n",
    "blocks = 128\n",
    "threads_per_block = 64\n",
    "\n",
    "hypot_stride[blocks, threads_per_block](d_a, d_b, d_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import testing\n",
    "# This assertion will fail until you successfully implement the hypot_stride kernel above\n",
    "testing.assert_almost_equal(np.hypot(a,b), d_c.copy_to_host(), decimal=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "## ‚è±Ô∏è Mesurer la Performance du Kernel `hypot_stride`\n",
    "\n",
    "Maintenant que nous avons optimis√© `hypot_stride` avec une **Grid Stride Loop**, il est temps d‚Äô√©valuer **ses performances** sur GPU. \n",
    "\n",
    "### üèÅ R√©f√©rence CPU : Mesurer la Performance de `np.hypot`\n",
    "\n",
    "Avant d‚Äôanalyser l‚Äôacc√©l√©ration GPU, nous devons d‚Äôabord **√©tablir une base de r√©f√©rence** en mesurant la performance de la version CPU avec **`np.hypot`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.hypot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### Acc√©l√©ration CPU avec Numba\n",
    "\n",
    "Apr√®s avoir mesur√© la performance de `np.hypot`, nous allons maintenant tester une **version optimis√©e pour le CPU** avec **Numba**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def numba_hypot(a, b):\n",
    "    return np.hypot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit numba_hypot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "### Ex√©cution Monothread sur le GPU\n",
    "\n",
    "Avant d‚Äô√©valuer l‚Äôacc√©l√©ration parall√®le du GPU, **lan√ßons notre kernel avec un seul thread** pour observer son comportement.\n",
    "\n",
    "1Ô∏è‚É£ **Lancer le kernel avec une grille de 1 bloc et 1 thread**.  \n",
    "2Ô∏è‚É£ **Utiliser `%time` au lieu de `%timeit`**, car CUDA a une file d‚Äôattente limit√©e.  \n",
    "3Ô∏è‚É£ **Ajouter un `cuda.synchronize()`** pour √©viter que l‚Äôhorloge CPU ne mesure du temps avant la fin du kernel.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time hypot_stride[1, 1](d_a, d_b, d_c); cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "Sans surprise, **ex√©cuter un kernel CUDA avec un seul thread** est **bien plus lent** que l‚Äôex√©cution sur CPU.  \n",
    "\n",
    "###  Ex√©cution Parall√®le sur le GPU\n",
    "\n",
    "Apr√®s avoir observ√© les limites d‚Äôun kernel ex√©cut√© **avec un seul thread**, lan√ßons-le maintenant en **mode massivement parall√®le** sur le GPU ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time hypot_stride[128, 64](d_a, d_b, d_c); cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "#### ‚ö° R√©sultat : Une Ex√©cution GPU Massivement Plus Rapide !\n",
    "\n",
    "Nous avons maintenant une acc√©l√©ration significative gr√¢ce au parall√©lisme GPU !\n",
    "\n",
    "### üìå **Comparaison des performances**\n",
    "| Version           | Temps d‚Äôex√©cution ‚è±Ô∏è  | Observations üìå |\n",
    "|------------------|-------------------|----------------|\n",
    "| **CPU (NumPy)**  | üêå Lent             | Bonne r√©f√©rence de base |\n",
    "| **Numba (CPU JIT)**  | ‚ö° Plus rapide que NumPy | Acc√©l√©ration CPU |\n",
    "| **CUDA (1 thread)** | üö® Tr√®s lent    | Mauvaise utilisation du GPU |\n",
    "| **CUDA (Parall√®le)** | üöÄ Ultra rapide !  | **Optimisation maximale** |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:8px; color:white; margin:10px 0; font-size:100%; font-family:Arial, sans-serif; background-color:#4682b4;\"><b>‚ö†Ô∏è 4.  Op√©rations Atomiques et √âviter les Conditions de Concurrence (Race Conditions)</b></div>\n",
    "\n",
    "\n",
    "\n",
    "### üîç **Pourquoi les race conditions sont-elles un probl√®me en CUDA ?**\n",
    "En programmation parall√®le, **plusieurs threads acc√®dent simultan√©ment √† la m√™me m√©moire globale**, ce qui peut cr√©er des **probl√®mes de concurrence** appel√©s **race conditions**.\n",
    "\n",
    "Deux types de conflits majeurs peuvent survenir :\n",
    "\n",
    "1Ô∏è‚É£ **Read-After-Write (RAW) hazard** :\n",
    "   - üîπ Un thread **lit** une variable pendant qu'un autre **√©crit** dessus.\n",
    "   - üîπ La valeur lue peut √™tre incorrecte ou incoh√©rente.\n",
    "  \n",
    "2Ô∏è‚É£ **Write-After-Write (WAW) hazard** :\n",
    "   - üîπ Deux threads **√©crivent en m√™me temps** sur la m√™me adresse m√©moire.\n",
    "   - üîπ Une seule des √©critures sera visible apr√®s l‚Äôex√©cution, rendant l‚Äôautre perdue.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **Strat√©gies pour √©viter les race conditions**\n",
    "‚úîÔ∏è **Assigner des √©l√©ments m√©moire uniques √† chaque thread**  \n",
    "‚úîÔ∏è **√âviter d'utiliser un m√™me tableau comme entr√©e et sortie** dans un seul appel kernel  \n",
    "‚úîÔ∏è **Utiliser le double-buffering** pour alterner entre deux tableaux m√©moire dans des algorithmes it√©ratifs  \n",
    "‚úîÔ∏è **Utiliser des op√©rations atomiques si plusieurs threads doivent modifier une m√™me valeur**  \n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö° **Pourquoi utiliser des op√©rations atomiques en CUDA ?**\n",
    "üí° **Exemple : Chaque thread incr√©mente un compteur global**  \n",
    "\n",
    "Pour cela, chaque thread doit :\n",
    "\n",
    "1Ô∏è‚É£ **Lire la valeur actuelle du compteur**  \n",
    "2Ô∏è‚É£ **Calculer `counter + 1`**  \n",
    "3Ô∏è‚É£ **√âcrire la nouvelle valeur en m√©moire globale**  \n",
    "\n",
    "üëâ **Probl√®me :** Un autre thread peut **modifier le compteur entre l‚Äô√©tape 1 et 3**, entra√Ænant des erreurs.\n",
    "\n",
    "---\n",
    "\n",
    "### üîí **Solution : les Op√©rations Atomiques CUDA**\n",
    "Une **op√©ration atomique** garantit que **la lecture, la modification et l‚Äô√©criture** d‚Äôune variable partag√©e s‚Äôeffectuent **en une seule √©tape indivisible**, emp√™chant ainsi les conflits entre threads.\n",
    "\n",
    "Numba prend en charge plusieurs **op√©rations atomiques** en CUDA, que vous pouvez retrouver ici :  \n",
    "üìñ [Liste des op√©rations atomiques CUDA dans Numba](http://numba.pydata.org/numba-doc/dev/cuda/intrinsics.html#supported-atomic-operations)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def thread_counter_race_condition(global_counter):\n",
    "    global_counter[0] += 1  # This is bad\n",
    "    \n",
    "@cuda.jit\n",
    "def thread_counter_safe(global_counter):\n",
    "    cuda.atomic.add(global_counter, 0, 1)  # Safely add 1 to offset 0 in global_counter array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets the wrong answer\n",
    "global_counter = cuda.to_device(np.array([0], dtype=np.int32))\n",
    "thread_counter_race_condition[64, 64](global_counter)\n",
    "\n",
    "print('Should be %d:' % (64*64), global_counter.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works correctly\n",
    "global_counter = cuda.to_device(np.array([0], dtype=np.int32))\n",
    "thread_counter_safe[64, 64](global_counter)\n",
    "\n",
    "print('Should be %d:' % (64*64), global_counter.copy_to_host())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "###  **Exercice : Impl√©menter un Kernel CUDA pour un Histogramme Acc√©l√©r√©**\n",
    "\n",
    "Dans cet exercice, vous allez **√©crire un kernel CUDA optimis√©** pour **calculer un histogramme en parall√®le** sur le GPU.  \n",
    "\n",
    "\n",
    "\n",
    "‚úÖ Prendre un **tableau de donn√©es en entr√©e**  \n",
    "‚úÖ D√©finir une **plage et un nombre de bins**  \n",
    "‚úÖ **Compter le nombre d‚Äô√©l√©ments** qui tombent dans chaque bin  \n",
    "‚úÖ **Optimiser** l‚Äôalgorithme pour **√©viter les conflits de threads**  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_histogram(x, xmin, xmax, histogram_out):\n",
    "    '''Increment bin counts in histogram_out, given histogram range [xmin, xmax).'''\n",
    "    # Note that we don't have to pass in nbins explicitly, because the size of histogram_out determines it\n",
    "    nbins = histogram_out.shape[0]\n",
    "    bin_width = (xmax - xmin) / nbins\n",
    "    \n",
    "    # This is a very slow way to do this with NumPy, but looks similar to what you will do on the GPU\n",
    "    for element in x:\n",
    "        bin_number = np.int32((element - xmin)/bin_width)\n",
    "        if bin_number >= 0 and bin_number < histogram_out.shape[0]:\n",
    "            # only increment if in range\n",
    "            histogram_out[bin_number] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size=10000, loc=0, scale=1).astype(np.float32)\n",
    "xmin = np.float32(-4.0)\n",
    "xmax = np.float32(4.0)\n",
    "histogram_out = np.zeros(shape=10, dtype=np.int32)\n",
    "\n",
    "cpu_histogram(x, xmin, xmax, histogram_out)\n",
    "\n",
    "histogram_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"background-color:#fae1e1; border-radius:8px; padding:15px; border-left:6px solid#bf2929; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "## üìù Instructions\n",
    "\n",
    "En utilisant une **Grid Stride Loop** et des **op√©rations atomiques**, impl√©mentez votre solution dans la cellule ci-dessous.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tap your solution here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Allocate memory on the GPU\n",
    "d_x = cuda.to_device(x)\n",
    "d_histogram_out = cuda.to_device(np.zeros(shape=10, dtype=np.int32))\n",
    "\n",
    "# Define execution configuration\n",
    "blocks = 128\n",
    "threads_per_block = 64\n",
    "\n",
    "# Launch kernel\n",
    "cuda_histogram[blocks, threads_per_block](d_x, xmin, xmax, d_histogram_out)\n",
    "\n",
    "# Copy result back to host\n",
    "histogram_cuda = d_histogram_out.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assertion will fail until you correctly implement `cuda_histogram`\n",
    "np.testing.assert_array_almost_equal(d_histogram_out.copy_to_host(), histogram_out, decimal=2)\n",
    "# Print results\n",
    "print(\"CPU Histogram:\", histogram_out)\n",
    "print(\"CUDA Histogram:\", histogram_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#eaf6fb; border-radius:8px; padding:20px; border-left:6px solid #4682b4; color:black; font-family:Arial, sans-serif;\">\n",
    "\n",
    "# <div style=\"text-align:center; border-radius:8px; padding:8px; color:white; margin:10px 0; font-size:100%; font-family:Arial, sans-serif; background-color:#4682b4;\"><b>üìù 5. Conslusion</b></div>\n",
    "\n",
    "\n",
    "\n",
    "Dans cette partie TP 3.2, vous avez appris √† :\n",
    "\n",
    "‚úÖ **√âcrire des kernels CUDA personnalis√©s** en Python et les ex√©cuter avec une **configuration d‚Äôex√©cution**.  \n",
    "‚úÖ **Utiliser les Grid Stride Loops** pour traiter efficacement **de grands ensembles de donn√©es** tout en optimisant **l‚Äôacc√®s m√©moire (memory coalescing)**.  \n",
    "‚úÖ **Exploiter les op√©rations atomiques** afin d‚Äô**√©viter les conditions de course** (*race conditions*) lors de calculs parall√®les.  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
